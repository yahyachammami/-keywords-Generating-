{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T11:01:08.025476Z",
     "iopub.status.busy": "2024-03-24T11:01:08.024574Z",
     "iopub.status.idle": "2024-03-24T11:01:08.030675Z",
     "shell.execute_reply": "2024-03-24T11:01:08.029428Z",
     "shell.execute_reply.started": "2024-03-24T11:01:08.025424Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T11:01:12.022596Z",
     "iopub.status.busy": "2024-03-24T11:01:12.021862Z",
     "iopub.status.idle": "2024-03-24T11:01:12.191595Z",
     "shell.execute_reply": "2024-03-24T11:01:12.190700Z",
     "shell.execute_reply.started": "2024-03-24T11:01:12.022550Z"
    }
   },
   "outputs": [],
   "source": [
    " df = pd.read_csv(\"/kaggle/input/medicaltranscriptions/mtsamples.csv\" , usecols=['description', 'keywords', \"transcription\" , \"medical_specialty\",\"sample_name\", \"medical_specialty\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T11:01:13.087044Z",
     "iopub.status.busy": "2024-03-24T11:01:13.086095Z",
     "iopub.status.idle": "2024-03-24T11:01:13.097951Z",
     "shell.execute_reply": "2024-03-24T11:01:13.096948Z",
     "shell.execute_reply.started": "2024-03-24T11:01:13.087001Z"
    }
   },
   "outputs": [],
   "source": [
    "df.dropna(axis = 0 , inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T11:01:16.613147Z",
     "iopub.status.busy": "2024-03-24T11:01:16.612368Z",
     "iopub.status.idle": "2024-03-24T11:01:16.631413Z",
     "shell.execute_reply": "2024-03-24T11:01:16.630351Z",
     "shell.execute_reply.started": "2024-03-24T11:01:16.613108Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"total_description\"] = \"description : \" + df[\"description\"] + \" medical specialty : \" + df[\"medical_specialty\"] + \" sample name : \" +  df[\"sample_name\"] + \" transcription : \" + df[\"transcription\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T11:01:17.078186Z",
     "iopub.status.busy": "2024-03-24T11:01:17.077130Z",
     "iopub.status.idle": "2024-03-24T11:01:17.087147Z",
     "shell.execute_reply": "2024-03-24T11:01:17.085755Z",
     "shell.execute_reply.started": "2024-03-24T11:01:17.078139Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import BartTokenizer, TFBartForConditionalGeneration\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "\n",
    "# Define the optimizer and loss function\n",
    "optimizer = Adam(learning_rate=5e-5)\n",
    "loss = SparseCategoricalCrossentropy(from_logits=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T11:01:35.782659Z",
     "iopub.status.busy": "2024-03-24T11:01:35.781992Z",
     "iopub.status.idle": "2024-03-24T11:01:38.291520Z",
     "shell.execute_reply": "2024-03-24T11:01:38.290387Z",
     "shell.execute_reply.started": "2024-03-24T11:01:35.782616Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBartForConditionalGeneration.\n",
      "\n",
      "All the layers of TFBartForConditionalGeneration were initialized from the model checkpoint at facebook/bart-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBartForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained BART model\n",
    "model = TFBartForConditionalGeneration.from_pretrained('facebook/bart-base')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T11:02:04.168923Z",
     "iopub.status.busy": "2024-03-24T11:02:04.167995Z",
     "iopub.status.idle": "2024-03-24T11:02:04.512187Z",
     "shell.execute_reply": "2024-03-24T11:02:04.510985Z",
     "shell.execute_reply.started": "2024-03-24T11:02:04.168874Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load BART tokenizer\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T11:02:05.382814Z",
     "iopub.status.busy": "2024-03-24T11:02:05.382151Z",
     "iopub.status.idle": "2024-03-24T11:02:05.501585Z",
     "shell.execute_reply": "2024-03-24T11:02:05.500442Z",
     "shell.execute_reply.started": "2024-03-24T11:02:05.382771Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9994869163673679\n"
     ]
    }
   ],
   "source": [
    "cnt=0\n",
    "for i in df['total_description']:\n",
    "    if(len(i.split())<=2000):\n",
    "        cnt=cnt+1\n",
    "print(cnt/len(df['total_description']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T11:02:06.199276Z",
     "iopub.status.busy": "2024-03-24T11:02:06.198372Z",
     "iopub.status.idle": "2024-03-24T11:02:06.213960Z",
     "shell.execute_reply": "2024-03-24T11:02:06.212808Z",
     "shell.execute_reply.started": "2024-03-24T11:02:06.199236Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9633145202668035\n"
     ]
    }
   ],
   "source": [
    "cnt=0\n",
    "for i in df['keywords']:\n",
    "    if(len(i.split())<=90):\n",
    "        cnt=cnt+1\n",
    "print(cnt/len(df['keywords']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using KERAS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T11:02:07.653085Z",
     "iopub.status.busy": "2024-03-24T11:02:07.652310Z",
     "iopub.status.idle": "2024-03-24T11:02:07.658392Z",
     "shell.execute_reply": "2024-03-24T11:02:07.657341Z",
     "shell.execute_reply.started": "2024-03-24T11:02:07.653041Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "max_input_length = 1000\n",
    "max_output_length = 150\n",
    "\n",
    "# Define the batch size and number of epochs for training\n",
    "batch_size = 4\n",
    "epochs = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T11:02:08.355657Z",
     "iopub.status.busy": "2024-03-24T11:02:08.354566Z",
     "iopub.status.idle": "2024-03-24T11:02:08.363700Z",
     "shell.execute_reply": "2024-03-24T11:02:08.362512Z",
     "shell.execute_reply.started": "2024-03-24T11:02:08.355607Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize_inputs_and_outputs(inputs, outputs):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    decoder_input_ids = []\n",
    "    labels = []\n",
    "    for i in range(len(inputs)):\n",
    "        input_text = inputs[i]\n",
    "        output_text = outputs[i]\n",
    "        input_tokenized = tokenizer.encode(input_text, max_length=max_input_length, padding='max_length', truncation=True, return_tensors='tf')\n",
    "        output_tokenized = tokenizer.encode(output_text, max_length=max_output_length, padding='max_length', truncation=True, return_tensors='tf')\n",
    "        input_ids.append(input_tokenized[0])\n",
    "        #attention_masks.append(input_tokenized['attention_mask'][0])\n",
    "        #decoder_input_ids.append(output_tokenized['input_ids'][0])\n",
    "        labels.append(output_tokenized[0])\n",
    "    return {'input_ids': tf.stack(input_ids),\n",
    "           # 'attention_mask': tf.stack(attention_masks),\n",
    "            #'decoder_input_ids': tf.stack(decoder_input_ids),\n",
    "            'labels': tf.stack(labels)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T11:02:08.966917Z",
     "iopub.status.busy": "2024-03-24T11:02:08.965743Z",
     "iopub.status.idle": "2024-03-24T11:02:08.972061Z",
     "shell.execute_reply": "2024-03-24T11:02:08.970890Z",
     "shell.execute_reply.started": "2024-03-24T11:02:08.966855Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T11:02:09.582154Z",
     "iopub.status.busy": "2024-03-24T11:02:09.581498Z",
     "iopub.status.idle": "2024-03-24T11:02:09.590221Z",
     "shell.execute_reply": "2024-03-24T11:02:09.589023Z",
     "shell.execute_reply.started": "2024-03-24T11:02:09.582114Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_highlight(text):\n",
    "    newText = text.lower()\n",
    "    newText = re.sub('[^\\w\\s\\d\\.]','',newText)\n",
    "    newText = ' '.join(newText.split())\n",
    "    newText = '_START_ '+ newText + ' _END_'\n",
    "    return newText\n",
    "def clean_body(text):\n",
    "    #newText = text[3:]\n",
    "    newText = text.lower()\n",
    "    newText = re.sub('[^\\w\\s\\d\\.]','',newText)\n",
    "    newText = ' '.join(newText.split())\n",
    "    tokens = [w for w in newText.split() ]\n",
    "    long_words=[]\n",
    "    for i in tokens:\n",
    "        if len(i)>=3:\n",
    "            long_words.append(i)   \n",
    "    return ( \" \".join(long_words)).strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T11:02:10.517412Z",
     "iopub.status.busy": "2024-03-24T11:02:10.517015Z",
     "iopub.status.idle": "2024-03-24T11:02:10.526393Z",
     "shell.execute_reply": "2024-03-24T11:02:10.525030Z",
     "shell.execute_reply.started": "2024-03-24T11:02:10.517376Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'description consult for laparoscopic gastric bypass. medical specialty bariatrics sample name laparoscopic gastric bypass consult transcription past medical history has difficulty climbing stairs difficulty with airline seats tying shoes used public seating and lifting objects off the floor. exercises three times week home and does cardio. has difficulty walking two blocks five flights stairs. difficulty with snoring. has muscle and joint pains including knee pain back pain foot and ankle pain and swelling. has gastroesophageal reflux disease.past surgical history includes reconstructive surgery his right hand years ago. social history currently single. has about ten drinks year. had smoked significantly until several months ago. now smokes less than three cigarettes day.family history heart disease both grandfathers grandmother with stroke and grandmother with diabetes. denies obesity and hypertension other family members.current medications none.allergies allergic penicillin.miscellaneouseating history has been going support groups for seven months with lynn holmberg greenwich and from eastchester new york and feels that are the appropriate program. had poor experience with the greenwich program. eating history not emotional eater. does not like sweets. likes big portions and carbohydrates. likes chicken and not steak. currently weighs 312 pounds. ideal body weight would 170 pounds. 142 pounds overweight. lost his excess body weight that would pounds and should weigh about 228.review systems negative for head neck heart lungs orthopedic and skin. specifically denies chest pain heart attack coronary artery disease congestive heart failure arrhythmia atrial fibrillation pacemaker high cholesterol pulmonary embolism high blood pressure cva venous insufficiency thrombophlebitis asthma shortness breath copd emphysema sleep apnea diabetes leg and foot swelling osteoarthritis rheumatoid arthritis hiatal hernia peptic ulcer disease gallstones infected gallbladder pancreatitis fatty liver hepatitis hemorrhoids rectal bleeding polyps incontinence stool urinary stress incontinence cancer. denies cellulitis pseudotumor cerebri meningitis encephalitis.physical examination alert and oriented cranial nerves iixii are intact. afebrile. vital signs are stable.'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_body(df['total_description'][1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T11:02:11.433546Z",
     "iopub.status.busy": "2024-03-24T11:02:11.432602Z",
     "iopub.status.idle": "2024-03-24T11:02:11.440370Z",
     "shell.execute_reply": "2024-03-24T11:02:11.439248Z",
     "shell.execute_reply.started": "2024-03-24T11:02:11.433495Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_START_ bariatrics laparoscopic gastric bypass weight loss programs gastric bypass atkins diet weight watchers body weight laparoscopic gastric weight loss pounds months weight laparoscopic band loss diets overweight lost _END_'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_highlight(df['keywords'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T11:02:13.423989Z",
     "iopub.status.busy": "2024-03-24T11:02:13.423175Z",
     "iopub.status.idle": "2024-03-24T11:02:13.433192Z",
     "shell.execute_reply": "2024-03-24T11:02:13.432031Z",
     "shell.execute_reply.started": "2024-03-24T11:02:13.423946Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a dataset from the input and output data\n",
    "class SummaryDataset(tf.keras.utils.Sequence):\n",
    "    def __init__(self, inputs, outputs, batch_size):\n",
    "        self.inputs = inputs\n",
    "        self.outputs = outputs\n",
    "        self.batch_size = batch_size\n",
    "        self.indexes = np.arange(len(inputs))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs) // self.batch_size\n",
    "    def __getitem__(self, indexes):\n",
    "        indexes = np.random.choice(self.indexes, size=self.batch_size, replace=False)\n",
    "        inputs_batch = [self.inputs[i] for i in indexes]\n",
    "        outputs_batch = [self.outputs[i] for i in indexes]\n",
    "        \n",
    "        inputs_batch = [clean_body(text) for text in inputs_batch]\n",
    "        outputs_batch = [clean_highlight(text) for text in outputs_batch]\n",
    "\n",
    "\n",
    "        #inputs_batch = self.inputs[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "        #outputs_batch = self.outputs[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "        return tokenize_inputs_and_outputs(inputs_batch, outputs_batch)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T11:02:14.755466Z",
     "iopub.status.busy": "2024-03-24T11:02:14.754367Z",
     "iopub.status.idle": "2024-03-24T11:02:14.762041Z",
     "shell.execute_reply": "2024-03-24T11:02:14.761005Z",
     "shell.execute_reply.started": "2024-03-24T11:02:14.755412Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create the dataloader for the training data\n",
    "train_dataset = SummaryDataset(df['total_description'][:-1000].tolist(), df['keywords'][:-1000].tolist(), batch_size=batch_size)\n",
    "val_dataset = SummaryDataset(df['total_description'][-1000:].tolist(), df['keywords'][-1000:].tolist(), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T11:02:15.970462Z",
     "iopub.status.busy": "2024-03-24T11:02:15.969645Z",
     "iopub.status.idle": "2024-03-24T11:02:16.055803Z",
     "shell.execute_reply": "2024-03-24T11:02:16.054820Z",
     "shell.execute_reply.started": "2024-03-24T11:02:15.970413Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(4, 1000), dtype=int32, numpy=\n",
       " array([[    0, 42739,  4885, ...,     1,     1,     1],\n",
       "        [    0, 42739,   235, ...,     1,     1,     1],\n",
       "        [    0, 42739, 13827, ...,     1,     1,     1],\n",
       "        [    0, 42739,  3186, ...,     1,     1,     1]], dtype=int32)>,\n",
       " 'labels': <tf.Tensor: shape=(4, 150), dtype=int32, numpy=\n",
       " array([[    0,  1215,  4014, 11328,  1215, 13938,  5966,  2017,  2775,\n",
       "         17301, 25743,   298, 20436, 24238,  6402,  1803,  4885, 15664,\n",
       "          4405, 30960,  1925,  1164, 18234, 18362,    23,   225,  1168,\n",
       "          1168, 25743,   298, 20436, 24238, 18134,  9309,  1215,     2,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1],\n",
       "        [    0,  1215,  4014, 11328,  1215,  1437,  4235,  1343,   119,\n",
       "         31466,  7753,  4753,     4,   524,   102,  4704, 10437,     9,\n",
       "          4398, 18741, 18741,   691,  4398, 18741,  2628,  4862,  8631,\n",
       "          1115,  8244, 10387,  2628,  4862,  8631,  1115,  8244, 14913,\n",
       "         39214,  1710, 34867,  1571,  4793, 18741, 14913, 39214,  2628,\n",
       "          4862,  8631,  1115,  8244, 18134,  9309,  1215,     2,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1],\n",
       "        [    0,  1215,  4014, 11328,  1215,   937,  6150,   435,  3566,\n",
       "         23665,  9212,   417, 34548,  1258,   184,  1021,   176, 13827,\n",
       "            15,  7642, 23665, 34548,  1258,  9212,   417, 18134,  9309,\n",
       "          1215,     2,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1],\n",
       "        [    0,  1215,  4014, 11328,  1215,   937,  6150,  2767,  2400,\n",
       "           847,    15,  2767,  2125,     9,  4049,  1093,   809,  2171,\n",
       "         13162,  2767,  1746,    23,   763, 36777,   784, 11937,  1258,\n",
       "         13162,   809, 18134,  9309,  1215,     2,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1]], dtype=int32)>}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T11:02:17.008539Z",
     "iopub.status.busy": "2024-03-24T11:02:17.007578Z",
     "iopub.status.idle": "2024-03-24T11:02:17.027641Z",
     "shell.execute_reply": "2024-03-24T11:02:17.026417Z",
     "shell.execute_reply.started": "2024-03-24T11:02:17.008483Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "loss = SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune the T5 model\n",
    "model.fit(train_dataset,validation_data= val_dataset , epochs= 10  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T13:04:16.857190Z",
     "iopub.status.busy": "2024-03-24T13:04:16.855885Z",
     "iopub.status.idle": "2024-03-24T13:04:49.385272Z",
     "shell.execute_reply": "2024-03-24T13:04:49.384176Z",
     "shell.execute_reply.started": "2024-03-24T13:04:16.857137Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: description :  Patient presented to the Bariatric Surgery Service for consideration of laparoscopic Roux-en-Y gastric bypass.  medical specialty :  Bariatrics sample name :  Bariatric Consult - Surgical Weight Loss - 4  transcription : HISTORY OF PRESENT ILLNESS:,  Ms. A is a 55-year-old female who presented to the Bariatric Surgery Service for consideration of laparoscopic Roux-en-Y gastric bypass.  The patient states that she has been overweight for approximately 35 years and has tried multiple weight loss modalities in the past including Weight Watchers, NutriSystem, Jenny Craig, TOPS, cabbage diet, grape fruit diet, Slim-Fast, Richard Simmons, as well as over-the-counter measures without any long-term sustainable weight loss.  At the time of presentation to the practice, she is 5 feet 6 inches tall with a weight of 285.4 pounds and a body mass index of 46.  She has obesity-related comorbidities, which includes hypertension and hypercholesterolemia.,PAST MEDICAL HISTORY:,  Significant for hypertension, for which the patient takes Norvasc and Lopressor for.  She also suffers from high cholesterol and is on lovastatin for this.  She has depression, for which she takes citalopram.  She also stated that she had a DVT in the past prior to her hysterectomy.  She also suffers from thyroid disease in the past though this is unclear, the nature of this.,PAST SURGICAL HISTORY: , Significant for cholecystectomy in 2008 for gallstones.  She also had a hysterectomy in 1994 secondary to hemorrhage.  The patient denies any other abdominal surgeries.,MEDICATIONS: , Norvasc 10 mg p.o. daily, Lopressor tartrate 50 mg p.o. b.i.d., lovastatin 10 mg p.o. at bedtime, citalopram 10 mg p.o. daily, aspirin 500 mg three times a day, which is currently stopped, vitamin D, Premarin 0.3 mg one tablet p.o. daily, currently stopped, omega-3 fatty acids, and vitamin D 50,000 units q. weekly.,ALLERGIES: , The patient denies allergies to medications and to latex.,SOCIAL HISTORY: , The patient is a homemaker.  She is married, with 2 children aged 22 and 28.  She is a lifelong nonsmoker and nondrinker.,FAMILY HISTORY:  ,Significant for high blood pressure and diabetes as well as cancer on her father side.  He did pass away from congestive heart failure.  Mother suffers from high blood pressure, cancer, and diabetes.  Her mother has passed away secondary to cancer.  She has two brothers one passed away from brain cancer.,REVIEW OF SYSTEMS: , Significant for ankle swelling.  The patient also wears glasses for vision and has dentures.  She does complain of shortness of breath with exertion.  She also suffers from hemorrhoids and frequent urination at night as well as weightbearing joint pain.  The patient denies ulcerative colitis, Crohn disease, bleeding diathesis, liver disease, or kidney disease.  She denies chest pain, cardiac disease, cancer, and stroke.,PHYSICAL EXAMINATION:  ,The patient is a well-nourished, well-developed female, in no distress.  Eye Exam:  Pupils equal and reactive to light.  Extraocular motions are intact.  Neck Exam:  No cervical lymphadenopathy.  Midline trachea.  No carotid bruits.  Nonpalpable thyroid.  Neuro Exam:  Gross motor strength in the upper and lower extremities, equal bilaterally with no focal neuro deficits noted.  Lung Exam:  Clear breath sounds without rhonchi or wheezes.  Cardiac Exam:  Regular rate and rhythm without murmur or bruits.  Abdominal Exam:  Positive bowel sounds.  Soft, nontender, obese, and nondistended abdomen.  Lap cholecystectomy scars noted.  No obvious hernias.  No organomegaly appreciated.  Lower extremity Exam:  Edema 1+.  Dorsalis pedis pulses 2+.,ASSESSMENT:  ,The patient is a 55-year-old female with a body mass index of 46, suffering from obesity-related comorbidities including hypertension and hypercholesterolemia, who presents to the practice for consideration of gastric bypass surgery.  The patient appears to be an excellent candidate for surgery and would benefit greatly from surgical weight loss in the management of her obesity-related comorbidities.,PLAN: , In preparation for surgery, we will obtain the usual baseline laboratory values including baseline vitamin levels.  I recommended the patient undergo an upper GI series prior to surgery due to find her upper GI anatomy.  Also the patient will meet with the dietitian and psychologist as per her usual routine.  I have recommended approximately six to eight weeks of Medifast for the patient to obtain a 10% preoperative weight loss in preparation for surgery.\n",
      "\n",
      " \n",
      "Keywords predictied: \n",
      "Real Keywords:    bariatrics, jenny craig, medifast, nutrisystem, richard simmons, slim-fast, tops, weight watchers, cabbage diet, grape fruit diet, roux-en-y, laparoscopic roux-en-y gastric bypass, weight loss modalities, surgical weight loss, body mass index, weight loss,\n",
      " \n",
      "\n",
      "Input: description :  Evaluation for elective surgical weight loss via the Lap-Band as opposed to gastric bypass. medical specialty :  Bariatrics sample name :  Bariatric Consult - Surgical Weight Loss - 2  transcription : PAST MEDICAL HISTORY:  ,She had a negative stress test four to five years ago.  She gets short of breath in walking about 30 steps.  She has had non-insulin dependent diabetes for about eight years now.  She has a left knee arthritis and history of hemorrhoids.,PAST SURGICAL HISTORY: , Pertinent for laparoscopic cholecystectomy, tonsillectomy, left knee surgery, and right breast lumpectomy.,PSYCHOLOGICAL HISTORY: , Negative except that she was rehabilitated for alcohol addiction in 1990.,SOCIAL HISTORY: , The patient is married.  She is an office manager for a gravel company.  Her spouse is also overweight.  She drinks on a weekly basis and she smokes,about two packs of cigarettes over a week's period of time.  She is doing this for about 35 years.,FAMILY HISTORY: , Diabetes and hypertension.,MEDICATIONS:,  Include Colestid 1 g daily, Actos 30 mg daily, Amaryl 2 mg daily, Soma, and meloxicam for her back pain.,ALLERGIES:,  She has no allergies; however, she does get tachycardic with caffeine, Sudafed, or phenylpropanolamine.,REVIEW OF SYSTEMS: , Otherwise, negative.,PHYSICAL EXAM: , This is a pleasant female in no acute distress.  Alert and oriented x 3.  HEENT:  Normocephalic, atraumatic.  Extraocular muscles intact, nonicteric sclerae.  Chest is clear.  Abdomen is obese, soft, nontender and nondistended.  Extremities show no edema, clubbing or cyanosis.,ASSESSMENT/PLAN: , This is a 51-year-old female with a BMI of 43 who is interested in the Lap-Band as opposed to gastric bypass.  ABC will be asking for a letter of medical necessity from XYZ.  She will also need an EKG and clearance for surgery.  She will also see my nutritionist and social worker and once this is completed, we will submit her to her insurance company for approval.\n",
      "\n",
      " \n",
      "Keywords predictied:   Bariatrics elective surgical weight loss via the Lap-Band gastric bypas\n",
      "Real Keywords:    bariatrics, elective surgical weight loss, surgical weight loss, weight loss, lap band, gastric bypass, loss, weight, lap, band, lost, gained, diabetes, gastric, bypass, overweight, surgical\n",
      " \n",
      "\n",
      "Input: description :  Chronic glossitis, xerostomia, probable environmental inhalant allergies, probable food allergies, and history of asthma. medical specialty :  Allergy / Immunology sample name :  Evaluation of Allergies  transcription : HISTORY:,  A 55-year-old female presents self-referred for the possibility of evaluation and treatment of allergies, diminished taste, xerostomia, gastroesophageal reflux disease, possible food allergies, chronic GI irritability, asthma, and environmental inhalant allergies.  Please refer to chart for history and physical and review of systems and detailed medical history.,IMPRESSION:  ,1.  Chronic glossitis/xerostomia/probable environmental inhalant allergies/probable food allergies/history of asthma.,2.  History of fibromyalgia.,3.  History of peptic ulcer disease, history of gastritis, history of gastroesophageal disease.,4.  History of chronic fatigue.,5.  History of hypothyroidism.,6.  History of depression.,7.  History of dysphagia.,RECOMMENDATIONS: , RAST allergy testing was ordered for food allergy evaluation.  The patient had previous allergy testing done less than one year ago iby Dr. X, which was requested.  The patient will follow up after RAST allergy testing for further treatment recommendations.  At this point, no changes in her medication were prescribed until her followup visit.\n",
      "\n",
      " \n",
      "Keywords predictied:   Allergy / Immunology allergies allergie\n",
      "Real Keywords:    allergy / immunology, chronic glossitis, xerostomia, probable environmental inhalant allergies, probable food allergies, environmental inhalant allergies, rast allergy testing, rast, inhalant, food, allergy\n",
      " \n",
      "\n",
      "Input: description :  This is a 14-month-old baby boy Caucasian who came in with presumptive diagnosis of Kawasaki with fever for more than 5 days and conjunctivitis, mild arthritis with edema, rash, resolving and with elevated neutrophils and thrombocytosis, elevated CRP and ESR.  medical specialty :  Allergy / Immunology sample name :  Kawasaki Disease - Discharge Summary  transcription : ADMITTING DIAGNOSIS: , Kawasaki disease.,DISCHARGE DIAGNOSIS:,  Kawasaki disease, resolving.,HOSPITAL COURSE:,  This is a 14-month-old baby boy Caucasian who came in with presumptive diagnosis of Kawasaki with fever for more than 5 days and conjunctivitis, mild arthritis with edema, rash, resolving and with elevated neutrophils and thrombocytosis, elevated CRP and ESR.  When he was sent to the hospital, he had a fever of 102.  Subsequently, the patient was evaluated and based on the criteria, he was started on high dose of aspirin and IVIG.  Echocardiogram was also done, which was negative.  IVIG was done x1, and between 12 hours of IVIG, he spiked fever again; it was repeated twice, and then after second IVIG, he did not spike any more fever.  Today, his fever and his rash have completely resolved.  He does not have any conjunctivitis and no redness of mucous membranes.  He is more calm and quite and taking good p.o.; so with a very close followup and a cardiac followup, he will be sent home.,DISCHARGE ACTIVITIES:,  Ad-lib.,DISCHARGE DIET: , PO ad-lib.,DISCHARGE MEDICATIONS: , Aspirin high dose 340 mg q.6h. for 1 day and then aspirin low dose 40 mg q.d. for 14 days and then Prevacid also to prevent his GI from aspirin 15 mg p.o. once a day.  He will be followed by his primary doctor in 2 to 3 days.  Cardiology for echo followup in 4 to 6 weeks and instructed not to give any vaccine in less than 11 months because of IVIG, all the live virus vaccine, and if he gets any rashes, any fevers, should go to primary care doctor as soon as possible.\n",
      "\n",
      " \n",
      "Keywords predictied:   Allergy / Immunology conjunctiviti\n",
      "Real Keywords:    allergy / immunology, mucous membranes, conjunctivitis, ad lib, kawasaki disease, vaccine, fever, aspirin\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "# Define the maximum length of the generated summaries\n",
    "max_summary_length = 90\n",
    "\n",
    "# Define a list of input texts to generate summaries for\n",
    "input_texts = df[\"total_description\"][-5:].tolist()\n",
    "output_texts =   df[\"keywords\"][-5:].tolist()\n",
    "bleu_scores = []\n",
    "# Generate summaries for the input texts\n",
    "for i  in range(1 , len(input_texts)):\n",
    "    # Tokenize the input text\n",
    "    input_text = input_texts[i]\n",
    "    output_text= output_texts[i]\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors='tf')\n",
    "\n",
    "    # Generate the summary using the bart model\n",
    "    summary_ids = model.generate(input_ids=input_ids,\n",
    "                                  max_length=max_summary_length,\n",
    "                                  num_beams=4,\n",
    "                                  no_repeat_ngram_size=2,\n",
    "                                  early_stopping=True)\n",
    "\n",
    "    # Decode the summary\n",
    "    summary_text = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    bleu_score = corpus_bleu(output_text.split()[:len(summary_text.split())], summary_text.split())\n",
    "    bleu_scores.append(bleu_score)\n",
    "    # Print the input text and summary\n",
    "    print(f\"Input: {input_text}\")\n",
    "    print(\"\\n \")\n",
    "    print(f\"Keywords predictied: {summary_text[7:-7]}\")\n",
    "    print(f\"Real Keywords:    {output_text}\\n \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T12:51:53.797338Z",
     "iopub.status.busy": "2024-03-24T12:51:53.796482Z",
     "iopub.status.idle": "2024-03-24T12:51:53.802665Z",
     "shell.execute_reply": "2024-03-24T12:51:53.801356Z",
     "shell.execute_reply.started": "2024-03-24T12:51:53.797297Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu_score = [0.6573046324907937, 0.6918912876154527, 0.5806030754582867]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bleu_scores\n",
    "\n",
    "print(\"bleu_score =\" , bleu_scores[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T11:50:09.317842Z",
     "iopub.status.busy": "2024-03-24T11:50:09.316986Z",
     "iopub.status.idle": "2024-03-24T11:50:09.325279Z",
     "shell.execute_reply": "2024-03-24T11:50:09.324175Z",
     "shell.execute_reply.started": "2024-03-24T11:50:09.317800Z"
    }
   },
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "# Initialize recognizer\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "# Function to listen and convert speech to text with pause detection\n",
    "def listen_and_convert():\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Speak now...\")\n",
    "        # Listen for audio with a pause threshold of 1 second\n",
    "        audio = recognizer.listen(source, phrase_time_limit=5)\n",
    "    try:\n",
    "        text = recognizer.recognize_google(audio)\n",
    "        return text\n",
    "    except sr.UnknownValueError:\n",
    "        return \"Sorry, I could not understand what you said.\"\n",
    "    except sr.RequestError as e:\n",
    "        return \"Could not request results from Google Speech Recognition service; {0}\".format(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T03:53:45.358097Z",
     "iopub.status.busy": "2024-03-24T03:53:45.357185Z",
     "iopub.status.idle": "2024-03-24T03:53:57.407354Z",
     "shell.execute_reply": "2024-03-24T03:53:57.406451Z",
     "shell.execute_reply.started": "2024-03-24T03:53:45.358056Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...bias_layer\n",
      "......vars\n",
      ".........0\n",
      "...layers\n",
      "......tf_bart_main_layer\n",
      ".........decoder\n",
      "............dropout\n",
      "...............vars\n",
      "............embed_positions\n",
      "...............vars\n",
      "..................0\n",
      "............embed_tokens\n",
      "...............vars\n",
      "..................0\n",
      "............layernorm_embedding\n",
      "...............vars\n",
      "..................0\n",
      "..................1\n",
      "............layers\n",
      "...............tf_bart_decoder_layer\n",
      "..................activation_dropout\n",
      ".....................vars\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................encoder_attn\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................k_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................out_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................q_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................v_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................vars\n",
      "..................encoder_attn_layer_norm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................fc1\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................fc2\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................final_layer_norm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................self_attn\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................k_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................out_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................q_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................v_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................vars\n",
      "..................self_attn_layer_norm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............tf_bart_decoder_layer_1\n",
      "..................activation_dropout\n",
      ".....................vars\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................encoder_attn\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................k_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................out_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................q_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................v_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................vars\n",
      "..................encoder_attn_layer_norm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................fc1\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................fc2\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................final_layer_norm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................self_attn\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................k_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................out_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................q_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................v_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................vars\n",
      "..................self_attn_layer_norm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............tf_bart_decoder_layer_2\n",
      "..................activation_dropout\n",
      ".....................vars\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................encoder_attn\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................k_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................out_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................q_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................v_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................vars\n",
      "..................encoder_attn_layer_norm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................fc1\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................fc2\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................final_layer_norm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................self_attn\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................k_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................out_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................q_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................v_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................vars\n",
      "..................self_attn_layer_norm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............tf_bart_decoder_layer_3\n",
      "..................activation_dropout\n",
      ".....................vars\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................encoder_attn\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................k_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................out_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................q_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................v_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................vars\n",
      "..................encoder_attn_layer_norm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................fc1\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................fc2\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................final_layer_norm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................self_attn\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................k_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................out_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................q_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................v_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................vars\n",
      "..................self_attn_layer_norm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............tf_bart_decoder_layer_4\n",
      "..................activation_dropout\n",
      ".....................vars\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................encoder_attn\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................k_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................out_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................q_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................v_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................vars\n",
      "..................encoder_attn_layer_norm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................fc1\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................fc2\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................final_layer_norm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................self_attn\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................k_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................out_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................q_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................v_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................vars\n",
      "..................self_attn_layer_norm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............tf_bart_decoder_layer_5\n",
      "..................activation_dropout\n",
      ".....................vars\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................encoder_attn\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................k_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................out_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................q_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................v_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................vars\n",
      "..................encoder_attn_layer_norm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................fc1\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................fc2\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................final_layer_norm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................self_attn\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................k_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................out_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................q_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................v_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................vars\n",
      "..................self_attn_layer_norm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "............vars\n",
      ".........encoder\n",
      "............dropout\n",
      "...............vars\n",
      "............embed_positions\n",
      "...............vars\n",
      "..................0\n",
      "............layernorm_embedding\n",
      "...............vars\n",
      "..................0\n",
      "..................1\n",
      "............layers\n",
      "...............tf_bart_encoder_layer\n",
      "..................activation_dropout\n",
      ".....................vars\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................fc1\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................fc2\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................final_layer_norm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................self_attn\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................k_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................out_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................q_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................v_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................vars\n",
      "..................self_attn_layer_norm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............tf_bart_encoder_layer_1\n",
      "..................activation_dropout\n",
      ".....................vars\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................fc1\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................fc2\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................final_layer_norm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................self_attn\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................k_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................out_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................q_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................v_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................vars\n",
      "..................self_attn_layer_norm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............tf_bart_encoder_layer_2\n",
      "..................activation_dropout\n",
      ".....................vars\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................fc1\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................fc2\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................final_layer_norm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................self_attn\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................k_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................out_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................q_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................v_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................vars\n",
      "..................self_attn_layer_norm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............tf_bart_encoder_layer_3\n",
      "..................activation_dropout\n",
      ".....................vars\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................fc1\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................fc2\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................final_layer_norm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................self_attn\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................k_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................out_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................q_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................v_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................vars\n",
      "..................self_attn_layer_norm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............tf_bart_encoder_layer_4\n",
      "..................activation_dropout\n",
      ".....................vars\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................fc1\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................fc2\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................final_layer_norm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................self_attn\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................k_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................out_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................q_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................v_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................vars\n",
      "..................self_attn_layer_norm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............tf_bart_encoder_layer_5\n",
      "..................activation_dropout\n",
      ".....................vars\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................fc1\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................fc2\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................final_layer_norm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................self_attn\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................k_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................out_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................q_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................v_proj\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................vars\n",
      "..................self_attn_layer_norm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "............vars\n",
      ".........vars\n",
      "...metrics\n",
      "......mean\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........100\n",
      ".........101\n",
      ".........102\n",
      ".........103\n",
      ".........104\n",
      ".........105\n",
      ".........106\n",
      ".........107\n",
      ".........108\n",
      ".........109\n",
      ".........11\n",
      ".........110\n",
      ".........111\n",
      ".........112\n",
      ".........113\n",
      ".........114\n",
      ".........115\n",
      ".........116\n",
      ".........117\n",
      ".........118\n",
      ".........119\n",
      ".........12\n",
      ".........120\n",
      ".........121\n",
      ".........122\n",
      ".........123\n",
      ".........124\n",
      ".........125\n",
      ".........126\n",
      ".........127\n",
      ".........128\n",
      ".........129\n",
      ".........13\n",
      ".........130\n",
      ".........131\n",
      ".........132\n",
      ".........133\n",
      ".........134\n",
      ".........135\n",
      ".........136\n",
      ".........137\n",
      ".........138\n",
      ".........139\n",
      ".........14\n",
      ".........140\n",
      ".........141\n",
      ".........142\n",
      ".........143\n",
      ".........144\n",
      ".........145\n",
      ".........146\n",
      ".........147\n",
      ".........148\n",
      ".........149\n",
      ".........15\n",
      ".........150\n",
      ".........151\n",
      ".........152\n",
      ".........153\n",
      ".........154\n",
      ".........155\n",
      ".........156\n",
      ".........157\n",
      ".........158\n",
      ".........159\n",
      ".........16\n",
      ".........160\n",
      ".........161\n",
      ".........162\n",
      ".........163\n",
      ".........164\n",
      ".........165\n",
      ".........166\n",
      ".........167\n",
      ".........168\n",
      ".........169\n",
      ".........17\n",
      ".........170\n",
      ".........171\n",
      ".........172\n",
      ".........173\n",
      ".........174\n",
      ".........175\n",
      ".........176\n",
      ".........177\n",
      ".........178\n",
      ".........179\n",
      ".........18\n",
      ".........180\n",
      ".........181\n",
      ".........182\n",
      ".........183\n",
      ".........184\n",
      ".........185\n",
      ".........186\n",
      ".........187\n",
      ".........188\n",
      ".........189\n",
      ".........19\n",
      ".........190\n",
      ".........191\n",
      ".........192\n",
      ".........193\n",
      ".........194\n",
      ".........195\n",
      ".........196\n",
      ".........197\n",
      ".........198\n",
      ".........199\n",
      ".........2\n",
      ".........20\n",
      ".........200\n",
      ".........201\n",
      ".........202\n",
      ".........203\n",
      ".........204\n",
      ".........205\n",
      ".........206\n",
      ".........207\n",
      ".........208\n",
      ".........209\n",
      ".........21\n",
      ".........210\n",
      ".........211\n",
      ".........212\n",
      ".........213\n",
      ".........214\n",
      ".........215\n",
      ".........216\n",
      ".........217\n",
      ".........218\n",
      ".........219\n",
      ".........22\n",
      ".........220\n",
      ".........221\n",
      ".........222\n",
      ".........223\n",
      ".........224\n",
      ".........225\n",
      ".........226\n",
      ".........227\n",
      ".........228\n",
      ".........229\n",
      ".........23\n",
      ".........230\n",
      ".........231\n",
      ".........232\n",
      ".........233\n",
      ".........234\n",
      ".........235\n",
      ".........236\n",
      ".........237\n",
      ".........238\n",
      ".........239\n",
      ".........24\n",
      ".........240\n",
      ".........241\n",
      ".........242\n",
      ".........243\n",
      ".........244\n",
      ".........245\n",
      ".........246\n",
      ".........247\n",
      ".........248\n",
      ".........249\n",
      ".........25\n",
      ".........250\n",
      ".........251\n",
      ".........252\n",
      ".........253\n",
      ".........254\n",
      ".........255\n",
      ".........256\n",
      ".........257\n",
      ".........258\n",
      ".........259\n",
      ".........26\n",
      ".........260\n",
      ".........261\n",
      ".........262\n",
      ".........263\n",
      ".........264\n",
      ".........265\n",
      ".........266\n",
      ".........267\n",
      ".........268\n",
      ".........269\n",
      ".........27\n",
      ".........270\n",
      ".........271\n",
      ".........272\n",
      ".........273\n",
      ".........274\n",
      ".........275\n",
      ".........276\n",
      ".........277\n",
      ".........278\n",
      ".........279\n",
      ".........28\n",
      ".........280\n",
      ".........281\n",
      ".........282\n",
      ".........283\n",
      ".........284\n",
      ".........285\n",
      ".........286\n",
      ".........287\n",
      ".........288\n",
      ".........289\n",
      ".........29\n",
      ".........290\n",
      ".........291\n",
      ".........292\n",
      ".........293\n",
      ".........294\n",
      ".........295\n",
      ".........296\n",
      ".........297\n",
      ".........298\n",
      ".........299\n",
      ".........3\n",
      ".........30\n",
      ".........300\n",
      ".........301\n",
      ".........302\n",
      ".........303\n",
      ".........304\n",
      ".........305\n",
      ".........306\n",
      ".........307\n",
      ".........308\n",
      ".........309\n",
      ".........31\n",
      ".........310\n",
      ".........311\n",
      ".........312\n",
      ".........313\n",
      ".........314\n",
      ".........315\n",
      ".........316\n",
      ".........317\n",
      ".........318\n",
      ".........319\n",
      ".........32\n",
      ".........320\n",
      ".........321\n",
      ".........322\n",
      ".........323\n",
      ".........324\n",
      ".........325\n",
      ".........326\n",
      ".........327\n",
      ".........328\n",
      ".........329\n",
      ".........33\n",
      ".........330\n",
      ".........331\n",
      ".........332\n",
      ".........333\n",
      ".........334\n",
      ".........335\n",
      ".........336\n",
      ".........337\n",
      ".........338\n",
      ".........339\n",
      ".........34\n",
      ".........340\n",
      ".........341\n",
      ".........342\n",
      ".........343\n",
      ".........344\n",
      ".........345\n",
      ".........346\n",
      ".........347\n",
      ".........348\n",
      ".........349\n",
      ".........35\n",
      ".........350\n",
      ".........351\n",
      ".........352\n",
      ".........353\n",
      ".........354\n",
      ".........355\n",
      ".........356\n",
      ".........357\n",
      ".........358\n",
      ".........359\n",
      ".........36\n",
      ".........360\n",
      ".........361\n",
      ".........362\n",
      ".........363\n",
      ".........364\n",
      ".........365\n",
      ".........366\n",
      ".........367\n",
      ".........368\n",
      ".........369\n",
      ".........37\n",
      ".........370\n",
      ".........371\n",
      ".........372\n",
      ".........373\n",
      ".........374\n",
      ".........375\n",
      ".........376\n",
      ".........377\n",
      ".........378\n",
      ".........379\n",
      ".........38\n",
      ".........380\n",
      ".........381\n",
      ".........382\n",
      ".........383\n",
      ".........384\n",
      ".........385\n",
      ".........386\n",
      ".........387\n",
      ".........388\n",
      ".........389\n",
      ".........39\n",
      ".........390\n",
      ".........391\n",
      ".........392\n",
      ".........393\n",
      ".........394\n",
      ".........395\n",
      ".........396\n",
      ".........397\n",
      ".........398\n",
      ".........399\n",
      ".........4\n",
      ".........40\n",
      ".........400\n",
      ".........401\n",
      ".........402\n",
      ".........403\n",
      ".........404\n",
      ".........405\n",
      ".........406\n",
      ".........407\n",
      ".........408\n",
      ".........409\n",
      ".........41\n",
      ".........410\n",
      ".........411\n",
      ".........412\n",
      ".........413\n",
      ".........414\n",
      ".........415\n",
      ".........416\n",
      ".........417\n",
      ".........418\n",
      ".........419\n",
      ".........42\n",
      ".........420\n",
      ".........421\n",
      ".........422\n",
      ".........423\n",
      ".........424\n",
      ".........425\n",
      ".........426\n",
      ".........427\n",
      ".........428\n",
      ".........429\n",
      ".........43\n",
      ".........430\n",
      ".........431\n",
      ".........432\n",
      ".........433\n",
      ".........434\n",
      ".........435\n",
      ".........436\n",
      ".........437\n",
      ".........438\n",
      ".........439\n",
      ".........44\n",
      ".........440\n",
      ".........441\n",
      ".........442\n",
      ".........443\n",
      ".........444\n",
      ".........445\n",
      ".........446\n",
      ".........447\n",
      ".........448\n",
      ".........449\n",
      ".........45\n",
      ".........450\n",
      ".........451\n",
      ".........452\n",
      ".........453\n",
      ".........454\n",
      ".........455\n",
      ".........456\n",
      ".........457\n",
      ".........458\n",
      ".........459\n",
      ".........46\n",
      ".........460\n",
      ".........461\n",
      ".........462\n",
      ".........463\n",
      ".........464\n",
      ".........465\n",
      ".........466\n",
      ".........467\n",
      ".........468\n",
      ".........469\n",
      ".........47\n",
      ".........470\n",
      ".........471\n",
      ".........472\n",
      ".........473\n",
      ".........474\n",
      ".........475\n",
      ".........476\n",
      ".........477\n",
      ".........478\n",
      ".........479\n",
      ".........48\n",
      ".........480\n",
      ".........481\n",
      ".........482\n",
      ".........483\n",
      ".........484\n",
      ".........485\n",
      ".........486\n",
      ".........487\n",
      ".........488\n",
      ".........489\n",
      ".........49\n",
      ".........490\n",
      ".........491\n",
      ".........492\n",
      ".........493\n",
      ".........494\n",
      ".........495\n",
      ".........496\n",
      ".........497\n",
      ".........498\n",
      ".........499\n",
      ".........5\n",
      ".........50\n",
      ".........500\n",
      ".........501\n",
      ".........502\n",
      ".........503\n",
      ".........504\n",
      ".........505\n",
      ".........506\n",
      ".........507\n",
      ".........508\n",
      ".........509\n",
      ".........51\n",
      ".........510\n",
      ".........511\n",
      ".........512\n",
      ".........513\n",
      ".........514\n",
      ".........515\n",
      ".........516\n",
      ".........517\n",
      ".........518\n",
      ".........52\n",
      ".........53\n",
      ".........54\n",
      ".........55\n",
      ".........56\n",
      ".........57\n",
      ".........58\n",
      ".........59\n",
      ".........6\n",
      ".........60\n",
      ".........61\n",
      ".........62\n",
      ".........63\n",
      ".........64\n",
      ".........65\n",
      ".........66\n",
      ".........67\n",
      ".........68\n",
      ".........69\n",
      ".........7\n",
      ".........70\n",
      ".........71\n",
      ".........72\n",
      ".........73\n",
      ".........74\n",
      ".........75\n",
      ".........76\n",
      ".........77\n",
      ".........78\n",
      ".........79\n",
      ".........8\n",
      ".........80\n",
      ".........81\n",
      ".........82\n",
      ".........83\n",
      ".........84\n",
      ".........85\n",
      ".........86\n",
      ".........87\n",
      ".........88\n",
      ".........89\n",
      ".........9\n",
      ".........90\n",
      ".........91\n",
      ".........92\n",
      ".........93\n",
      ".........94\n",
      ".........95\n",
      ".........96\n",
      ".........97\n",
      ".........98\n",
      ".........99\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-03-24 03:53:45         2599\n",
      "variables.h5                                   2024-03-24 03:53:48   1673940076\n",
      "metadata.json                                  2024-03-24 03:53:45           64\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the model\n",
    "with open('model2.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T07:01:19.781188Z",
     "iopub.status.busy": "2024-03-24T07:01:19.780232Z",
     "iopub.status.idle": "2024-03-24T07:01:20.094065Z",
     "shell.execute_reply": "2024-03-24T07:01:20.092620Z",
     "shell.execute_reply.started": "2024-03-24T07:01:19.781148Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'model2.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_27/1474909867.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# load the saved model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model2.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mmodel2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'model2.pkl'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# load the saved model\n",
    "with open('model2.pkl', 'rb') as f:\n",
    "    model2 = pickle.load(f)\n",
    "\n",
    "# use the model for prediction or other tasks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T06:59:16.898459Z",
     "iopub.status.busy": "2024-03-24T06:59:16.897514Z",
     "iopub.status.idle": "2024-03-24T06:59:17.003697Z",
     "shell.execute_reply": "2024-03-24T06:59:17.002105Z",
     "shell.execute_reply.started": "2024-03-24T06:59:16.898401Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_27/2401559803.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Define a list of input texts to generate summaries for\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0minput_texts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"description\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Generate summaries for the input texts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Define the maximum length of the generated summaries\n",
    "max_summary_length = 90\n",
    "\n",
    "# Define a list of input texts to generate summaries for\n",
    "input_texts = df[\"description\"][:2].tolist()\n",
    "\n",
    "# Generate summaries for the input texts\n",
    "for input_text in input_texts:\n",
    "    # Tokenize the input text\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors='tf')\n",
    "\n",
    "    # Generate the summary using the T5 model\n",
    "    summary_ids = model.generate(input_ids=input_ids,\n",
    "                                  max_length=max_summary_length,\n",
    "                                  num_beams=4,\n",
    "                                  no_repeat_ngram_size=2,\n",
    "                                  early_stopping=True)\n",
    "\n",
    "    # Decode the summary\n",
    "    summary_text = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    # Print the input text and summary\n",
    "    print(f\"Input: {input_text}\")\n",
    "    print(f\"Summary: {summary_text}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-08T15:01:46.161949Z",
     "iopub.status.busy": "2023-05-08T15:01:46.161444Z",
     "iopub.status.idle": "2023-05-08T15:01:46.216024Z",
     "shell.execute_reply": "2023-05-08T15:01:46.214963Z",
     "shell.execute_reply.started": "2023-05-08T15:01:46.161915Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bart_for_conditional_generation_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " model (TFBartMainLayer)     multiple                  139420416 \n",
      "                                                                 \n",
      " final_logits_bias (BiasLaye  multiple                 50265     \n",
      " r)                                                              \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 139,470,681\n",
      "Trainable params: 139,420,416\n",
      "Non-trainable params: 50,265\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-08T15:06:47.029979Z",
     "iopub.status.busy": "2023-05-08T15:06:47.029207Z",
     "iopub.status.idle": "2023-05-08T15:06:47.038906Z",
     "shell.execute_reply": "2023-05-08T15:06:47.037676Z",
     "shell.execute_reply.started": "2023-05-08T15:06:47.029940Z"
    }
   },
   "outputs": [],
   "source": [
    "input_ids = tokenizer.encode_plus(input_text, return_tensors='tf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-08T18:46:47.442112Z",
     "iopub.status.busy": "2023-05-08T18:46:47.441395Z",
     "iopub.status.idle": "2023-05-08T18:46:57.798263Z",
     "shell.execute_reply": "2023-05-08T18:46:57.796821Z",
     "shell.execute_reply.started": "2023-05-08T18:46:47.442075Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /opt/conda/lib/python3.7/site-packages (1.5.13)\n",
      "Requirement already satisfied: python-slugify in /opt/conda/lib/python3.7/site-packages (from kaggle) (8.0.1)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.7/site-packages (from kaggle) (2022.12.7)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from kaggle) (2.28.2)\n",
      "Requirement already satisfied: urllib3 in /opt/conda/lib/python3.7/site-packages (from kaggle) (1.26.14)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.7/site-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: six>=1.10 in /opt/conda/lib/python3.7/site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from kaggle) (4.64.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /opt/conda/lib/python3.7/site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->kaggle) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->kaggle) (3.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install kaggle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T07:54:44.368172Z",
     "iopub.status.busy": "2024-03-24T07:54:44.367116Z",
     "iopub.status.idle": "2024-03-24T07:54:44.399021Z",
     "shell.execute_reply": "2024-03-24T07:54:44.397150Z",
     "shell.execute_reply.started": "2024-03-24T07:54:44.368124Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transformers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_27/1918443971.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'transformers' is not defined"
     ]
    }
   ],
   "source": [
    "import keras \n",
    "print(transformers.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 64826,
     "sourceId": 127612,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30446,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
